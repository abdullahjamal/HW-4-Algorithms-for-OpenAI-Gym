{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamal/AI_assign/lib/python3.5/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "def compute_modified_reward(next_state):\n",
    "    modified_reward = np.square(max(0, next_state[0] + 0.5))\n",
    "    if next_state[0] >= 0.5: \n",
    "        modified_reward += 1.0\n",
    "    return modified_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state_size = 2\n",
    "actions_size = 3\n",
    "net_hidden_state = 32\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "max_iters = 500\n",
    "max_t = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self,input_state_size = input_state_size,\n",
    "                 actions_size = actions_size, \n",
    "                 net_hidden_state = net_hidden_state,\n",
    "                 lr = lr,\n",
    "                 name='Net'):\n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            self.states = tf.placeholder(tf.float32,[None,input_state_size])\n",
    "            self.actions = tf.placeholder(tf.int32,[None])\n",
    "            self.hidden_layer = tf.contrib.layers.fully_connected(\n",
    "                self.states, \n",
    "                net_hidden_state)\n",
    "            self.hidden_layer = tf.contrib.layers.fully_connected(\n",
    "                self.hidden_layer, \n",
    "                net_hidden_state)\n",
    "            self.out = tf.contrib.layers.fully_connected(\n",
    "                self.hidden_layer, \n",
    "                actions_size,\n",
    "                activation_fn = None)\n",
    "            \n",
    "            self.one_hot_actions = tf.one_hot(\n",
    "                self.actions, \n",
    "                actions_size)\n",
    "            \n",
    "            self.probabilities = tf.nn.softmax(self.out)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.out,\n",
    "                                                                                labels=self.one_hot_actions))\n",
    "            self.optimizer = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
    "    \n",
    "    def get_action(self,state):\n",
    "        feed_dict = {self.states : np.array([state])}\n",
    "        \n",
    "        probs = sess.run(self.probabilities,feed_dict = feed_dict)\n",
    "        \n",
    "        return np.random.choice(actions_size,p=probs[0])\n",
    "        #$return np.argmax(probs[0])\n",
    "    \n",
    "    \n",
    "    def train(self,batch):\n",
    "        \n",
    "        states , actions = zip(*batch)\n",
    "        \n",
    "        states = np.array(states)\n",
    "        actions = np.array(actions)\n",
    "        \n",
    "        feed_dict = {self.states : states, self.actions : actions}\n",
    "        \n",
    "        _, pro = sess.run([self.optimizer,self.probabilities],feed_dict = feed_dict)        \n",
    "        \n",
    "        \n",
    "        #print(pro)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "net = Net(name = 'Net',net_hidden_state= net_hidden_state,lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -178.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -172.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -184.0\n",
      "Now Testing\n",
      "Total reward: -176.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -183.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -185.0\n",
      "Now Testing\n",
      "Total reward: -166.0\n",
      "Now Testing\n",
      "Total reward: -196.0\n",
      "Now Testing\n",
      "Total reward: -172.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -194.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -179.0\n",
      "Now Testing\n",
      "Total reward: -169.0\n",
      "Now Testing\n",
      "Total reward: -176.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -170.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -177.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -173.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -183.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -175.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -177.0\n",
      "Now Testing\n",
      "Total reward: -181.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -174.0\n",
      "Now Testing\n",
      "Total reward: -178.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -175.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -179.0\n",
      "Now Testing\n",
      "Total reward: -176.0\n",
      "Now Testing\n",
      "Total reward: -169.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -174.0\n",
      "Now Testing\n",
      "Total reward: -170.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -193.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -162.0\n",
      "Now Testing\n",
      "Total reward: -190.0\n",
      "Now Testing\n",
      "Total reward: -193.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -189.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -113.0\n",
      "Now Testing\n",
      "Total reward: -170.0\n",
      "Now Testing\n",
      "Total reward: -127.0\n",
      "Now Testing\n",
      "Total reward: -169.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -145.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -159.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -145.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -185.0\n",
      "Now Testing\n",
      "Total reward: -178.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -140.0\n",
      "Now Testing\n",
      "Total reward: -176.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -185.0\n",
      "Now Testing\n",
      "Total reward: -185.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -141.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -159.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -113.0\n",
      "Now Testing\n",
      "Total reward: -166.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -135.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -180.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -124.0\n",
      "Now Testing\n",
      "Total reward: -175.0\n",
      "Now Testing\n",
      "Total reward: -178.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -178.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -182.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -181.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -173.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -174.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -184.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -173.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -168.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -181.0\n",
      "Now Testing\n",
      "Total reward: -162.0\n",
      "Now Testing\n",
      "Total reward: -148.0\n",
      "Now Testing\n",
      "Total reward: -165.0\n",
      "Now Testing\n",
      "Total reward: -163.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -161.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -122.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -159.0\n",
      "Now Testing\n",
      "Total reward: -164.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -173.0\n",
      "Now Testing\n",
      "Total reward: -161.0\n",
      "Now Testing\n",
      "Total reward: -166.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -168.0\n",
      "Now Testing\n",
      "Total reward: -124.0\n",
      "Now Testing\n",
      "Total reward: -161.0\n",
      "Now Testing\n",
      "Total reward: -193.0\n",
      "Now Testing\n",
      "Total reward: -164.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -161.0\n",
      "Now Testing\n",
      "Total reward: -194.0\n",
      "Now Testing\n",
      "Total reward: -175.0\n",
      "Now Testing\n",
      "Total reward: -153.0\n",
      "Now Testing\n",
      "Total reward: -120.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -118.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -168.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -129.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -127.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -122.0\n",
      "Now Testing\n",
      "Total reward: -117.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -123.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -153.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -157.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -160.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -161.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -113.0\n",
      "Now Testing\n",
      "Total reward: -110.0\n",
      "Now Testing\n",
      "Total reward: -145.0\n",
      "Now Testing\n",
      "Total reward: -194.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -120.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -118.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -112.0\n",
      "Now Testing\n",
      "Total reward: -198.0\n",
      "Now Testing\n",
      "Total reward: -126.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -112.0\n",
      "Now Testing\n",
      "Total reward: -114.0\n",
      "Now Testing\n",
      "Total reward: -158.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -153.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -159.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -177.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -114.0\n",
      "Now Testing\n",
      "Total reward: -126.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -120.0\n",
      "Now Testing\n",
      "Total reward: -118.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -121.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -117.0\n",
      "Now Testing\n",
      "Total reward: -117.0\n",
      "Now Testing\n",
      "Total reward: -124.0\n",
      "Now Testing\n",
      "Total reward: -114.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -117.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -138.0\n",
      "Now Testing\n",
      "Total reward: -119.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -157.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -156.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -148.0\n",
      "Now Testing\n",
      "Total reward: -146.0\n",
      "Now Testing\n",
      "Total reward: -157.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -160.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -146.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -153.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -123.0\n",
      "Now Testing\n",
      "Total reward: -181.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -153.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -157.0\n",
      "Now Testing\n",
      "Total reward: -147.0\n",
      "Now Testing\n",
      "Total reward: -139.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -117.0\n",
      "Now Testing\n",
      "Total reward: -147.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -177.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -154.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -155.0\n",
      "Now Testing\n",
      "Total reward: -163.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -148.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -120.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -152.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -121.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -120.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -113.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -116.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -169.0\n",
      "Now Testing\n",
      "Total reward: -119.0\n",
      "Now Testing\n",
      "Total reward: -144.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -147.0\n",
      "Now Testing\n",
      "Total reward: -145.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -115.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -144.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -144.0\n",
      "Now Testing\n",
      "Total reward: -114.0\n",
      "Now Testing\n",
      "Total reward: -149.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -144.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -146.0\n",
      "Now Testing\n",
      "Total reward: -151.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -200.0\n",
      "Now Testing\n",
      "Total reward: -148.0\n",
      "Now Testing\n",
      "Total reward: -145.0\n",
      "Now Testing\n",
      "Total reward: -148.0\n",
      "Now Testing\n",
      "Total reward: -150.0\n",
      "Now Testing\n",
      "Total reward: -99.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import bisect\n",
    "import time\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    start_index = int(max_iters * 80 / 100)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        total_reward_list = []\n",
    "        trajectory_list = []\n",
    "\n",
    "\n",
    "        for i in np.arange(max_iters):\n",
    "            total_reward = 0.0\n",
    "            trajectory = []\n",
    "            state = env.reset()\n",
    "\n",
    "            for s in np.arange(max_t):\n",
    "                action = net.get_action(state)\n",
    "\n",
    "                next_state,reward,done,_ = env.step(action)\n",
    "                #print(reward)\n",
    "                modified_reward = compute_modified_reward(next_state)\n",
    "                total_reward += modified_reward\n",
    "                trajectory.append((state,action))\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            index = bisect.bisect(total_reward_list,total_reward)\n",
    "            total_reward_list.insert(index,total_reward)\n",
    "            trajectory_list.insert(index,trajectory)\n",
    "        #import pdb;pdb.set_trace()\n",
    "\n",
    "        state_action_pairs = []\n",
    "\n",
    "        for trajectory in trajectory_list[start_index:]:\n",
    "            for state_action_pair in trajectory:\n",
    "                state_action_pairs.append(state_action_pair)\n",
    "\n",
    "\n",
    "        random.shuffle(state_action_pairs)\n",
    "\n",
    "        batches = [state_action_pairs[k:k+batch_size] for k in np.arange(0,len(state_action_pairs),batch_size)]\n",
    "\n",
    "        for batch in batches:\n",
    "            net.train(batch)\n",
    "\n",
    "        print(\"Now Testing\")\n",
    "        #test\n",
    "\n",
    "        state = env.reset()\n",
    "        env.render()\n",
    "        time.sleep(0.01)\n",
    "        total_reward = 0.0\n",
    "        for s in np.arange(max_t):\n",
    "            action = net.get_action(state)\n",
    "            state,reward,done,_ = env.step(action)\n",
    "            total_reward += reward\n",
    "            env.render()\n",
    "            time.sleep(0.01)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "\n",
    "        env.close()\n",
    "        print(\"Total reward:\",total_reward)\n",
    "\n",
    "        if total_reward > -110:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
